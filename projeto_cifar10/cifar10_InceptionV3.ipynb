{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cifar10_InceptionV3.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7RVsYZLEpEWs"
      },
      "source": [
        "# Imports necessários\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RxwCQNZWIL8y",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ivDUkUNdINH2",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NU3IAZ02G6VA",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "amfzqn1Oo7Om"
      },
      "source": [
        "# Download do dataset do cifar10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oXiJjX0jfx1o",
        "colab": {}
      },
      "source": [
        "(set_treino, set_validacao), dataset_info = tfds.load(\n",
        "    'cifar10',\n",
        "    split=['train[:70%]', 'train[70%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X0p1sOEHf0JF"
      },
      "source": [
        "# Análise sobre o conjunto de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DrIUV3V0xDL_",
        "colab": {}
      },
      "source": [
        "num_classes = dataset_info.features['label'].num_classes\n",
        "\n",
        "num_treino_exemplos = 0\n",
        "num_validacao_exemplos = 0\n",
        "\n",
        "for exemplo in set_treino:\n",
        "  num_treino_exemplos += 1\n",
        "\n",
        "for exemplo in set_validacao:\n",
        "  num_validacao_exemplos += 1\n",
        "\n",
        "print('Numero total de classes: {}'.format(num_classes))\n",
        "print('Numero total de imagens de treino: {}'.format(num_treino_exemplos))\n",
        "print('Numero total de imagens de validação: {} \\n'.format(num_validacao_exemplos))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UlFZ_hwjCLgS"
      },
      "source": [
        "Ajustando tamanho das imagens "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W4lDPkn2cpWZ",
        "colab": {}
      },
      "source": [
        "for i, exemplo in enumerate(set_treino.take(5)):\n",
        "  print('Image {} shape: {} label: {}'.format(i+1, exemplo[0].shape, exemplo[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JzV457OXreQP"
      },
      "source": [
        "#Transfer Learning da InceptionV3\n",
        "\n",
        "Será feito o transfer learning utilizando o Tensorflow hub\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "we_ftzQxNf7e",
        "colab": {}
      },
      "source": [
        "IMAGE_RES = 299\n",
        "\n",
        "def format_image(image, label):\n",
        "  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
        "  return image, label\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "batches_de_treino = set_treino.shuffle(num_treino_exemplos//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "batches_de_validacao= set_validacao.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "(set_treino, set_validacao), dataset_info = tfds.load(\n",
        "    'tf_flowers', \n",
        "    with_info=True, \n",
        "    as_supervised=True, \n",
        "    split=['train[:70%]', 'train[70%:]'],\n",
        ")\n",
        "batches_de_treino = set_treino.shuffle(num_treino_exemplos//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "batches_de_validacao = set_validacao.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "URL = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
        "feature_extractor = hub.KerasLayer(URL,\n",
        "  input_shape=(IMAGE_RES, IMAGE_RES, 3),\n",
        "  trainable=False)\n",
        "\n",
        "model_inception = tf.keras.Sequential([\n",
        "  feature_extractor,\n",
        "  tf.keras.layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model_inception.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OHbXQqIquFxQ"
      },
      "source": [
        "### Treinando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3n0Wb9ylKd8R",
        "colab": {}
      },
      "source": [
        "model_inception.compile(\n",
        "  optimizer='adam', \n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "history = model_inception.fit(batches_de_treino,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=batches_de_validacao)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}